<html>
	<head>
	</head>
	<body>
		<h1> Task 1 </h1>
			<br>For this task, I implemented basic rasterization. <br>
			<br>To ensure that it was at least as efficient as checking the smallest bounding box containing the triangle,
			I construct the bounding box by using  
			<br>int max_height = MAX(floor(y0),floor(y1),floor(y2)); <br>
    			<br> int max_width = MAX(floor(x0),floor(x1),floor(x2)); <br>
    			<br> int min_height = MIN(floor(y0),floor(y1),floor(y2)); <br>
    			<br> int min_width = MIN(floor(x0),floor(x1),floor(x2)); <br>
			<br> Then I check each i,j in the above bounds. For each pixel, I compute the mid point as i + 0.5, j+ 0.5 (with appropriate typecasting)<br>
			<br>and apply the in-triangle test. Instead of just checking > 0, I check for  >= 0 since we want the points on the edge to be considered as well.<br>
			<br> Also, before performing the in-triangle test, I account for the orientation of the triangle by computing the cross-product of (x1 - x0, y1 - y0) <br>
			<br> with (x2 - x1, y2 - y1). If the orientation is positive (cross product > 0), I don't change anything. If it is negative I swap x1,x2 and y1,y2 <br>
			<br> below is an image of test4 <br>
			<img src="Screen Shot 2024-02-25 at 8.51.46 AM.png" alt="test4" width="400" 
     height="500">

		<h1> Task 2 </h1>
		<br> This task was supersampling. For this, I first modified the sample buffer to be of size sample_size*width*height rather than just width*height <br>
		<br> Then, for each pixel in the bounding box, I have two inner loops (with variables k and l) running from 1 to sqrt(sample_size) where apply the triangle test on a point (x,y) <br>
		<br> Where x = i + (k + 0.5)/sqrt(sample_size) and y = j + (k + 0.5)/sqrt(sample_size).I also have an auxillary index variable that I increment whenever the innermost loop is completed. <br>
		<br> I do this since I set sample_buffer[sample_rate * (y * width + x) + index] = color if the triangle test returns true. <br>
		<br> When I finish checking all the "sub-pixels", I reset index to be 0. <br>
		<br> Then, when rendering, to move from sample to frame buffer, I use the following loop <br>
		<br> for (int ind = 0; ind less than sample_rate; ind++) col = col + sample_buffer[sample_rate * (y * width + x) + ind]; <br>
		<br> Finally, I avergae it out by dividing by sample size <br>
		<br> Here is a rendering of test4 <br>
		<img src="Screen Shot 2024-02-25 at 10.41.47 AM.png" alt="ss1" width="400" 
     height="500">
		<br> For an alternative method, I also tried out jittered sampling. For this, I simply changed the x = i + (k + 0.5)/sqrt(sample_size) to be x = i + rnad(0,1)<br>
		<br> where the random numbers are from the uniform distrbution. Below is a rendering of the same image with jittered sampling <br>
		<img src="Screen Shot 2024-02-25 at 10.42.53 AM.png" alt="ss1" width="400" 
     height="500">
        


		<h1> Task 3</h1>
		<br> Here is the robot. He is dancing - I rotated the torso by 30 degrees and the leg by 45 degrees. <br>
		<img src="Screen Shot 2024-02-25 at 9.25.14 AM.png" alt="robot" width="400" 
     height="500">

		<h1> Task 4</h1>

		<br> This task was for barycentric coordinates. The barycentric coordinate system takes any point (x,y) and turns it into a point (alpha, beta, gamma) <br>
		<br> Where (alpha, beta, gamma) satisfy x = alpha*A_x + beta*B_x + gamma*C_x and y = alpha*A_y + beta*B_y + gamma*C_y and the additional constraint of alpha + beta + gamma = 1. <br>
		<br> So, we are essentailly representing each point as a weighted average of the points of a triangle. An example is shown below where we have three vertices - R,G,B <br>
		<img src="Screen Shot 2024-02-25 at 9.49.05 AM.png" alt="simple triangle" width="400" 
     height="500">
		<br> We can see how all the colors blend together towards the centre of the triangle <br>
		<br> Here is the color wheel rendering of test7 <br>
		<img src="Screen Shot 2024-02-25 at 9.32.21 AM.png" alt="test7" width="400" 
     height="500">

		<h1> Task 5 </h1>
		<br> For this task, we exploit the fact that barycentric coordinates are presevred when we move to texture space. <br>
			
		<br> an approximate algorithm is described as follows- First we compute the barycentric coordinates of the point in the triangle, <br>
		<br> Then we move to texture space by the points given to us as arguments. In the original space, we'd compute a point x,y as alpha*A + beta*B  + gamma*C <br>
		<br> But since barycentric coordinates are preserved through the mapping, we can compute u,v as alpha*(u0,v0) + beta*(u1,v1)  + gamma*(u2,v2) <br>
		<br> Then we cal get texel and assign a color to (i,j) accordingly.

		<br> For the different kinds, there's billinear and nearest. for nearest, We first scale u,v and then round to nearest integer coordinates <br>
		<br> and get the texel corresponding to this scaled rounded coordinate <br>
		<br> For billinear, we get the texels of the 4 nearest integer coordinates and take a weighted average of all 4, where the weights are just as in the lecture slides <br>
		<br> Here I've included images of texmap/test1.svg using both linear and nearest using sample rates of 1 and 16 respectively <br>
		<br> Sample rate 1 <br>
		<div class="container">
		  <img src="Screen Shot 2024-02-25 at 4.32.31 PM.png" alt="Image 1" class="image">
		  <img src="Screen Shot 2024-02-25 at 4.32.43 PM.png" alt="Image 2" class="image">
		</div>
		<br> sample rate 16 < br>
		<div class="container">
		  <img src="Screen Shot 2024-02-25 at 4.33.53 PM.png" alt="Image 1" class="image">
		  <img src="Screen Shot 2024-02-25 at 4.34.46 PM.png" alt="Image 2" class="image">
		</div>
		<br> We can see that billinear appears slighly blurry while the images using nearest appear very crisp. <br>
		<br> This is to be expected since billinear filtering takes a weighted average of neighboring points. It is similar to the barycentric color triangle in that sense. <br>
		<br> The differences between the two will likely be the most pronounced when we are rendering images that have rapid and discontinuous transitions between distinct textures. <br>
		<br> the boundaries between both the distinct regions will be sharp for the nearest case. But for the billinear case, the boundary will be very blurred and almost invisible. <br>
		
			
		
		



		<h1> Task 6 </h1>
		<br> for this task, we needed to implement level sampling. Level sampling is the idea of storing our textures at different levels of granularity. <br>
		<br> When rendering an image, we can choose which "level" to sample from based on our desired resolution. Higher resolution would mean finer details and more granularity and lower would mean sampling from a texture map with lower granularity. <br>
		<br> In this assignment, I decided what level was required by computing the partial x and y derivatives at the point of interest. <br>
		<br> As we noted in the previous task, barycentric coordinates are preserved when we go from xy space to uv space. We can use this to compute the partial derivates by finding the barycentric coordinates of the points (x+1,y) and (x,y+1) <br>
		<br> Then, we can compute d/dx by a finite difference formula -> uv(x+1,y) - uv(x,y). Where uv() is the function that takes points from xy to uv space. We can do the same for the y-derivative and then use the formula from the lecture slides to compute L <br>
		<br> L is just the log of the max 2-norm of our partial derivatives. The intutition for this formula can be thought of as follows- If we have a higher rate of change when we go from xy to uv space, that means that the textures in our image are changing rapidly across space and so we'd need a higher level. <br>
		<h2> Tradeoffs-</h2>
		<br> If we look at tradeoffs between the three approahces, we can first consider memory usage. Pixel sampling is the cheapest since we don't really take up any extra space. <br>
		<br> On the other hand supersampling requires memory directly proportional to the number of samples per pixel, while sampling requires an even larger memory requirement since we store a L texel maps for each level. <br>
		<br> In terms of computation time, supersampling is probably the most expensive since the number of flops required scales with the number of samples, on the other hand the number of flops is pretty much constant for pixel and level sampling is always constant. <br>
		<br> With these tradeoffs in mind, it seems like supersampling and level mapping, while being hard to scale have much stronger anti-aliasing power since they allow for much higher granularity in images. <br>
		<br> Pixel mapping, while cheap, doesn't really have any scope for scaling and cannot perform exceedingly well on it's own. Regardless of which pixel map technique we use, the image stays relatively the same for the most part. <br>
		<br> Below are some images for different settings tried on a funky image I found online -
		<div class="container">
		  <img src="Screen Shot 2024-02-25 at 5.52.53 PM.png" alt="Nearest pixel, lvl 0" class="image">
		  <img src="Screen Shot 2024-02-25 at 5.53.19 PM.png" alt="billinear pixel, lvl 0" class="image">
		  <img src="Screen Shot 2024-02-25 at 5.53.46 PM.png" alt="nearest level, nearest pixel" class="image">
		  <img src="Screen Shot 2024-02-25 at 5.54.01 PM.png" alt="nearest level, billinear pixel" class="image">
		</div>
		
		

	</body>
</html>
